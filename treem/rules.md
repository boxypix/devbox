<!-- rules.md -->

# Rules — Дерево продуктовых метрик (B2C)

Этот документ — правила работы с “деревом метрик” в мини-веб-аппе и в продуктовой команде: как выбирать метрики, как их считать, как не врать себе и как связывать ветки дерева между собой.

---

## 0) Технический контракт дерева (для mini-app)

### 0.1 Source of truth
- Единственный источник данных для UI: `tree.data.js`.
- UI в `index.html` должен читать данные из глобального `METRIC_TREE` (`globalThis.METRIC_TREE`).
- `tree.json` (если появится) считается вспомогательным экспортом, но не primary source для рендера.

### 0.2 Гарантии для корректного рендера
- `index.html` подключает `tree.data.js` **до** скрипта рендера.
- Если `METRIC_TREE` отсутствует или сломан по структуре, UI должен показывать понятную ошибку (а не пустой экран).
- Перед релизом дерева выполняется smoke-check структуры (id/code/name, children-массив, уникальность id).

---

## 1) Базовые принципы

### 1.1 Одна North Star (NSM) — и она про ценность
- **NSM должна измерять полученную пользователем ценность**, а не активность ради активности.
- NSM обычно строится вокруг **core value event** (1–2 события максимум).

**Запрещено как NSM:**
- MAU/DAU “просто так”
- просмотры экранов
- “время в приложении” без связи с ценностью

**Разрешено (пример формата):**
- `Weekly users who completed core action`
- `Users with successful outcome per week`
- `Core value completions per day`

---

## 2) Правила структуры дерева

### 2.1 Ветки дерева
Дерево разделено на ветки:
- **Acquisition** — привлечение
- **Activation** — получение first value
- **Engagement** — регулярность/глубина использования
- **Retention** — возвраты/удержание
- **Monetization** — доход
- **Quality** — стабильность/скорость (влияет на все ветки)
- **Unit economics** — экономика роста (LTV/CAC, payback)

**Правило:** любые изменения в продукте должны быть “привязаны” минимум к одной ветке и объяснять, как это повлияет на NSM.

---

## 3) Метрики: определения и договорённости

### 3.1 Единые словари и дефиниции
Перед сравнением метрик фиксируем:
- кто считается **Active user**
- что такое **Session**
- что считается **Install**
- как считаются **возвраты** (календарные дни vs rolling window)
- какие события считаются **core value event**

**Правило:** если нет определения — метрики “врут” и сравнивать нельзя.

### 3.2 Формулы и единицы измерения
Для каждой метрики обязаны быть:
- **формула**
- **период** (день/неделя/месяц)
- **сегменты** (по умолчанию)
- **источник** (аналитика/стор/сервер)
- **ограничения** (что не учитываем)

---

## 4) Ведущие и итоговые метрики

### 4.1 Leading vs Lagging
- **Leading** — ранний сигнал (Activation rate, TTV, Core action frequency).
- **Lagging** — итог (Retention, Revenue, LTV).

**Правило:** на каждую инициативу выбираем:
- 1 ведущую метрику (быстро покажет “работает/нет”)
- 1 итоговую (подтвердит эффект позже)

---

## 5) Срезы и когорты (без этого — самообман)

### 5.1 Когорты обязательны
Смотрим метрики по когортам:
- **канал** (organic / paid / referral)
- **страна/язык**
- **версия приложения**
- **вариант paywall/онбординга**
- **сегмент пользователя** (новый/возвращённый/платящий)

**Правило:** любые “средние” метрики без когорт — только для общего здоровья, не для решений.

### 5.2 Минимальный набор retention
База для B2C:
- **D1 / D7 / D30** + cohort retention

---

## 6) Анти-паттерны (что запрещено)

### 6.1 Vanity metrics
Запрещено принимать решения по:
- просмотрам страниц
- времени в приложении
- количеству кликов без связи с value
- росту установок без проверки retention

### 6.2 “Сделали — значит улучшили”
Запрещено считать “выпуск фичи” успехом.
Успех = **изменение метрики** в правильной когорте.

### 6.3 Оптимизация одной ветки в ущерб другой
Примеры:
- подняли PaywallCVR, но просели AHA/D1
- улучшили CTR, но упал CVR install (кликбейт)
- снизили CPI, но retention стал хуже (дешёвый мусорный трафик)

**Правило:** инициатива не считается успешной, если ломает NSM-драйверы.

---

## 7) Правила качества данных

### 7.1 События и naming
- События должны быть **стабильны** по именам и параметрам.
- Нельзя менять смысл события “тихо”.

Рекомендации:
- `snake_case`
- versioned events при изменении семантики (`event_v2`)
- параметры фиксируются в схеме

### 7.2 Дедупликация и робастность
- дедуплицировать повторы (двойные отправки)
- учитывать оффлайн/переоткрытия
- хранить server-side подтверждения для критичных событий оплаты

---

## 8) Эксперименты и изменения

### 8.1 Любая инициатива = гипотеза
Стандарт гипотезы:
- **Если** мы сделаем X (изменение),
- **то** метрика Y изменится на Z (ожидаемый эффект),
- **потому что** причина/механизм,
- **мы проверим** за период T в когорте K.

### 8.2 A/B тесты
- фиксировать primary metric (1 шт.)
- ограничить вторичные метрики (2–3)
- заранее определить критерии остановки
- следить за quality guardrails (crash, latency, refunds)

---

## 9) Guardrails (метрики-ограничители)

Для каждой ветки должны быть “красные линии”, например:
- **CrashFree** не ниже X%
- **Latency p95** не выше Y
- **RefundRate** не выше Z
- **Rating** не ниже N

**Правило:** если guardrail ухудшился — релиз/изменение считается проблемным, даже если основная метрика выросла.

---

## 10) Как “читать” дерево (логика причинности)

### 10.1 Диагностика падения NSM
Порядок проверки:
1) **Quality** (краши/латентность/ANR)
2) **Activation** (AHA, TTV)
3) **Retention** (D1/D7/D30 по когортам)
4) **Acquisition** (каналы, CVR, CPI)
5) **Monetization** (paywall timing, refunds, churn платящих)

**Правило:** не лезем чинить monetization, если activation/quality больны.

---

## 11) Формат узлов дерева (как заполнять tree.data.js)

Каждый узел должен иметь:
- `id`, `code`, `name`
- `short` (1 строка)
- `why` (1–3 предложения)
- `formula` (если применимо)
- `howImprove` (3–6 пунктов)
- `pitfalls` (2–5 пунктов)
- `related` (коды связанных метрик)
- `tags` (leading/lagging/proxy/feature/etc.)

Дополнительно:
- `id` должен быть уникальным во всём дереве.
- `children` либо отсутствует, либо является массивом узлов.
- Для узлов-веток (`Acquisition`, `Retention` и т.д.) допустимо не заполнять `formula`, но `why` обязателен.

---

## 12) Минимальный “боевой” набор для любого B2C

Обязательное ядро:
- **NSM**
- Acquisition: CTR, CVR_install, ChannelMix
- Activation: AHA, TTV
- Engagement: CoreActionFreq, Stickiness
- Retention: D1/D7/D30 + cohort retention
- Monetization (если есть): PaywallCVR, ARPU, RefundRate, LTV
- Quality: CrashFree, Latency p95, Rating
- Unit economics: CAC, LTV/CAC, Payback

---

## 13) Чеклист перед тем как “делать вывод”

- [ ] Есть определения активного пользователя, сессии и core value event
- [ ] Метрика смотрится по когортам (канал/страна/версия)
- [ ] Есть leading + lagging на инициативу
- [ ] Guardrails не ухудшились
- [ ] Изменение статистически/практически значимо (не шум)
- [ ] Понимаем механизм: *почему* метрика изменилась

### 13.1 Чеклист перед обновлением UI-дерева
- [ ] `tree.data.js` загружается без синтаксических ошибок
- [ ] В корне есть `METRIC_TREE` с `id`, `code`, `name`
- [ ] Нет дубликатов `id`
- [ ] Поиск в UI работает по `name/code/short/why/tags`
- [ ] После загрузки отображаются верхние ветки и выбирается NSM по умолчанию
- [ ] При ошибке данных UI показывает человекочитаемое сообщение

---

## 14) Ответственность и дисциплина

- **Владелец метрики** обязан:
  - держать актуальные определения
  - следить за корректностью событий
  - обновлять описания узлов дерева
- **Команда** обязана:
  - не спорить “на вкус”
  - опираться на дерево причинности
  - фиксировать гипотезы и результаты

---

## 15) TL;DR (самое короткое правило)
**NSM растёт только когда растёт ценность.**  
Ценность растёт через Activation → Retention → Engagement, при нормальном Quality и адекватной Economics.  
Если нет когорт и дефиниций — это не аналитика, а гадание.
